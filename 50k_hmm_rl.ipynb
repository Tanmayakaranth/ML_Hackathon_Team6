{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c3e8645",
   "metadata": {},
   "source": [
    "# Intelligent Hangman Solver - HMM + RL\n",
    "\n",
    "This notebook implements an intelligent Hangman solver using:\n",
    "- **Hidden Markov Model (HMM)** for learning letter patterns by position and context\n",
    "- **Q-Learning (Reinforcement Learning)** agent for decision making\n",
    "\n",
    "The system trains on a corpus of words and evaluates performance on a test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dbb9e5",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dc8ace6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "import pickle\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74454a1e",
   "metadata": {},
   "source": [
    "## 2. Hidden Markov Model Class\n",
    "\n",
    "The HMM learns letter patterns by position and context, creating separate models for each word length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95cf9486",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenMarkovModel:\n",
    "    \"\"\"\n",
    "    HMM for Hangman - learns letter patterns by position and context\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.models_by_length = {}\n",
    "    \n",
    "    def train(self, corpus_words):\n",
    "        \"\"\"Train HMM on corpus, creating separate models for each word length\"\"\"\n",
    "        print(\"Training HMM...\")\n",
    "        \n",
    "        # Group words by length\n",
    "        words_by_length = defaultdict(list)\n",
    "        for word in corpus_words:\n",
    "            word = word.lower().strip()\n",
    "            if word.isalpha():\n",
    "                words_by_length[len(word)].append(word)\n",
    "        \n",
    "        # Train model for each length\n",
    "        for length, words in words_by_length.items():\n",
    "            self.models_by_length[length] = self._train_length_model(words, length)\n",
    "        \n",
    "        print(f\"Trained HMM for {len(self.models_by_length)} different word lengths\")\n",
    "    \n",
    "    def _train_length_model(self, words, length):\n",
    "        \"\"\"Train model for specific word length\"\"\"\n",
    "        model = {\n",
    "            'position_freq': defaultdict(Counter),  # position -> letter -> count\n",
    "            'letter_freq': Counter(),                # letter -> count\n",
    "            'bigram_freq': Counter(),                # bigram -> count\n",
    "            'trigram_freq': Counter(),               # trigram -> count\n",
    "            'total_words': len(words)\n",
    "        }\n",
    "        \n",
    "        for word in words:\n",
    "            # Position-based frequencies\n",
    "            for i, char in enumerate(word):\n",
    "                model['position_freq'][i][char] += 1\n",
    "                model['letter_freq'][char] += 1\n",
    "            \n",
    "            # Bigram frequencies\n",
    "            for i in range(len(word) - 1):\n",
    "                bigram = word[i:i+2]\n",
    "                model['bigram_freq'][bigram] += 1\n",
    "            \n",
    "            # Trigram frequencies\n",
    "            for i in range(len(word) - 2):\n",
    "                trigram = word[i:i+3]\n",
    "                model['trigram_freq'][trigram] += 1\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def predict(self, masked_word, guessed_letters):\n",
    "        \"\"\"\n",
    "        Predict probability distribution over alphabet given current game state\n",
    "        Returns: dict of {letter: score}\n",
    "        \"\"\"\n",
    "        length = len(masked_word)\n",
    "        model = self.models_by_length.get(length)\n",
    "        \n",
    "        if not model:\n",
    "            # Fallback to closest length\n",
    "            closest_length = min(self.models_by_length.keys(), \n",
    "                                key=lambda x: abs(x - length))\n",
    "            model = self.models_by_length[closest_length]\n",
    "        \n",
    "        scores = {}\n",
    "        alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "        \n",
    "        # Count revealed letters for adaptive weighting\n",
    "        revealed_count = sum(1 for c in masked_word if c != '_')\n",
    "        progress = revealed_count / length if length > 0 else 0\n",
    "        \n",
    "        for char in alphabet:\n",
    "            if char in guessed_letters:\n",
    "                continue\n",
    "            \n",
    "            score = 0.0\n",
    "            \n",
    "            # 1. Position-based scoring (INCREASED weight)\n",
    "            for i, c in enumerate(masked_word):\n",
    "                if c == '_':\n",
    "                    pos_freq = model['position_freq'][i].get(char, 0)\n",
    "                    score += (pos_freq / model['total_words']) * 3.0  # Increased from 1.0\n",
    "            \n",
    "            # 2. Context-based scoring (bigrams) - INCREASED weight\n",
    "            for i, c in enumerate(masked_word):\n",
    "                if c == '_':\n",
    "                    # Left context\n",
    "                    if i > 0 and masked_word[i-1] != '_':\n",
    "                        bigram = masked_word[i-1] + char\n",
    "                        score += model['bigram_freq'].get(bigram, 0) / model['total_words'] * 5.0  # Increased from 2.0\n",
    "                    \n",
    "                    # Right context\n",
    "                    if i < len(masked_word) - 1 and masked_word[i+1] != '_':\n",
    "                        bigram = char + masked_word[i+1]\n",
    "                        score += model['bigram_freq'].get(bigram, 0) / model['total_words'] * 5.0  # Increased from 2.0\n",
    "            \n",
    "            # 3. Trigram context (INCREASED weight when available)\n",
    "            for i, c in enumerate(masked_word):\n",
    "                if c == '_':\n",
    "                    # _XY pattern\n",
    "                    if i < len(masked_word) - 2:\n",
    "                        if masked_word[i+1] != '_' and masked_word[i+2] != '_':\n",
    "                            trigram = char + masked_word[i+1] + masked_word[i+2]\n",
    "                            score += model['trigram_freq'].get(trigram, 0) / model['total_words'] * 8.0  # Increased from 3.0\n",
    "                    \n",
    "                    # X_Y pattern\n",
    "                    if i > 0 and i < len(masked_word) - 1:\n",
    "                        if masked_word[i-1] != '_' and masked_word[i+1] != '_':\n",
    "                            trigram = masked_word[i-1] + char + masked_word[i+1]\n",
    "                            score += model['trigram_freq'].get(trigram, 0) / model['total_words'] * 8.0  # Increased from 3.0\n",
    "                    \n",
    "                    # XY_ pattern\n",
    "                    if i > 1:\n",
    "                        if masked_word[i-2] != '_' and masked_word[i-1] != '_':\n",
    "                            trigram = masked_word[i-2] + masked_word[i-1] + char\n",
    "                            score += model['trigram_freq'].get(trigram, 0) / model['total_words'] * 8.0  # Increased from 3.0\n",
    "            \n",
    "            # 4. Overall letter frequency (adaptive based on progress)\n",
    "            # Early game: use more frequency, late game: use less\n",
    "            freq_weight = 2.0 * (1.0 - progress)  # Decreases as game progresses\n",
    "            score += model['letter_freq'].get(char, 0) / (model['total_words'] * length) * freq_weight\n",
    "            \n",
    "            # 5. Vowel bonus early in the game\n",
    "            if progress < 0.3 and char in 'aeiou':\n",
    "                score += 0.5\n",
    "            \n",
    "            scores[char] = score\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def save(self, filename):\n",
    "        \"\"\"Save model to file\"\"\"\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(self.models_by_length, f)\n",
    "        print(f\"HMM saved to {filename}\")\n",
    "    \n",
    "    def load(self, filename):\n",
    "        \"\"\"Load model from file\"\"\"\n",
    "        with open(filename, 'rb') as f:\n",
    "            self.models_by_length = pickle.load(f)\n",
    "        print(f\"HMM loaded from {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc4a23d",
   "metadata": {},
   "source": [
    "## 3. Reinforcement Learning Agent Class\n",
    "\n",
    "Q-Learning agent that combines learned Q-values with HMM predictions for optimal letter selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d76f1309",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLAgent:\n",
    "    \"\"\"\n",
    "    Q-Learning agent for Hangman\n",
    "    \"\"\"\n",
    "    def __init__(self, hmm, alpha=0.2, gamma=0.98, epsilon=1.0, \n",
    "                 epsilon_decay=0.9985, epsilon_min=0.05):\n",
    "        self.hmm = hmm\n",
    "        self.q_table = defaultdict(lambda: defaultdict(float))\n",
    "        self.alpha = alpha          # Learning rate (increased from 0.1)\n",
    "        self.gamma = gamma          # Discount factor (increased from 0.95)\n",
    "        self.epsilon = epsilon      # Exploration rate\n",
    "        self.epsilon_decay = epsilon_decay  # Slower decay (was 0.995)\n",
    "        self.epsilon_min = epsilon_min  # Higher minimum (was 0.01)\n",
    "        \n",
    "    def get_state_key(self, masked_word, guessed_letters, lives_left):\n",
    "        \"\"\"Create state representation\"\"\"\n",
    "        guessed_str = ''.join(sorted(guessed_letters))\n",
    "        return f\"{masked_word}:{guessed_str}:{lives_left}\"\n",
    "    \n",
    "    def choose_action(self, masked_word, guessed_letters, lives_left, training=True):\n",
    "        \"\"\"\n",
    "        Choose action using epsilon-greedy with HMM guidance\n",
    "        \"\"\"\n",
    "        hmm_scores = self.hmm.predict(masked_word, guessed_letters)\n",
    "        available_letters = list(hmm_scores.keys())\n",
    "        \n",
    "        if not available_letters:\n",
    "            return None\n",
    "        \n",
    "        state_key = self.get_state_key(masked_word, guessed_letters, lives_left)\n",
    "        \n",
    "        # Epsilon-greedy exploration\n",
    "        if training and random.random() < self.epsilon:\n",
    "            # Explore: weighted random based on HMM scores\n",
    "            total_score = sum(hmm_scores.values())\n",
    "            if total_score > 0:\n",
    "                probs = [hmm_scores[letter] / total_score for letter in available_letters]\n",
    "                action = np.random.choice(available_letters, p=probs)\n",
    "            else:\n",
    "                action = random.choice(available_letters)\n",
    "        else:\n",
    "            # Exploit: combine Q-values with HMM scores\n",
    "            best_action = None\n",
    "            best_score = float('-inf')\n",
    "            \n",
    "            for letter in available_letters:\n",
    "                q_value = self.q_table[state_key][letter]\n",
    "                hmm_score = hmm_scores[letter]\n",
    "                # Increased HMM weight from 0.3 to 0.7 - HMM is very informative!\n",
    "                combined_score = q_value + hmm_score * 0.7\n",
    "                \n",
    "                if combined_score > best_score:\n",
    "                    best_score = combined_score\n",
    "                    best_action = letter\n",
    "            \n",
    "            action = best_action\n",
    "        \n",
    "        return action\n",
    "    \n",
    "    def update_q_value(self, state, action, reward, next_state):\n",
    "        \"\"\"Update Q-value using Q-learning formula\"\"\"\n",
    "        current_q = self.q_table[state][action]\n",
    "        \n",
    "        # Get max Q-value for next state\n",
    "        if next_state in self.q_table:\n",
    "            max_next_q = max(self.q_table[next_state].values()) if self.q_table[next_state] else 0\n",
    "        else:\n",
    "            max_next_q = 0\n",
    "        \n",
    "        # Q-learning update\n",
    "        new_q = current_q + self.alpha * (reward + self.gamma * max_next_q - current_q)\n",
    "        self.q_table[state][action] = new_q\n",
    "    \n",
    "    def train(self, corpus_words, episodes=5000, verbose=True):\n",
    "        \"\"\"Train agent on corpus - INCREASED episodes\"\"\"\n",
    "        print(f\"Training RL agent for {episodes} episodes...\")\n",
    "        \n",
    "        episode_rewards = []\n",
    "        episode_wins = []\n",
    "        \n",
    "        for episode in range(episodes):\n",
    "            # Random word from corpus\n",
    "            word = random.choice(corpus_words).lower().strip()\n",
    "            if not word.isalpha():\n",
    "                continue\n",
    "            \n",
    "            total_reward = self.play_episode(word, training=True)\n",
    "            episode_rewards.append(total_reward)\n",
    "            \n",
    "            # Decay epsilon\n",
    "            if self.epsilon > self.epsilon_min:\n",
    "                self.epsilon *= self.epsilon_decay\n",
    "            \n",
    "            if verbose and (episode + 1) % 500 == 0:\n",
    "                recent_rewards = episode_rewards[-500:]\n",
    "                avg_reward = np.mean(recent_rewards)\n",
    "                print(f\"Episode {episode + 1}/{episodes} - Avg Reward: {avg_reward:.2f} - Epsilon: {self.epsilon:.3f}\")\n",
    "        \n",
    "        print(\"Training complete!\")\n",
    "        return episode_rewards\n",
    "    \n",
    "    def play_episode(self, word, training=True):\n",
    "        \"\"\"Play one episode of Hangman\"\"\"\n",
    "        masked_word = '_' * len(word)\n",
    "        guessed_letters = set()\n",
    "        lives_left = 6\n",
    "        total_reward = 0\n",
    "        \n",
    "        while lives_left > 0 and '_' in masked_word:\n",
    "            state_key = self.get_state_key(masked_word, guessed_letters, lives_left)\n",
    "            \n",
    "            # Choose action\n",
    "            action = self.choose_action(masked_word, guessed_letters, lives_left, training)\n",
    "            if action is None:\n",
    "                break\n",
    "            \n",
    "            # Take action\n",
    "            guessed_letters.add(action)\n",
    "            \n",
    "            # Check if correct\n",
    "            if action in word:\n",
    "                # Reveal letters\n",
    "                new_masked = ''.join([c if c in guessed_letters else '_' for c in word])\n",
    "                revealed_count = new_masked.count('_') - masked_word.count('_')\n",
    "                revealed_count = abs(revealed_count)\n",
    "                \n",
    "                # IMPROVED: Reward scales with letters revealed\n",
    "                reward = 15 * revealed_count  # Increased from 10\n",
    "                \n",
    "                # Bonus for early correct guesses (more lives = better)\n",
    "                reward += lives_left * 2\n",
    "                \n",
    "                # Check if won\n",
    "                if '_' not in new_masked:\n",
    "                    reward += 150  # Increased win bonus from 100\n",
    "                \n",
    "                masked_word = new_masked\n",
    "            else:\n",
    "                # IMPROVED: Penalty increases as lives decrease (avoid risky moves)\n",
    "                penalty = -25 - (6 - lives_left) * 5  # Gets worse as lives decrease\n",
    "                reward = penalty\n",
    "                lives_left -= 1\n",
    "                \n",
    "                # Extra penalty if almost lost\n",
    "                if lives_left == 0:\n",
    "                    reward -= 100\n",
    "            \n",
    "            total_reward += reward\n",
    "            \n",
    "            # Update Q-value if training\n",
    "            if training:\n",
    "                next_state_key = self.get_state_key(masked_word, guessed_letters, lives_left)\n",
    "                self.update_q_value(state_key, action, reward, next_state_key)\n",
    "        \n",
    "        return total_reward\n",
    "    \n",
    "    def play_game(self, word):\n",
    "        \"\"\"Play game without training (for evaluation)\"\"\"\n",
    "        word = word.lower().strip()\n",
    "        masked_word = '_' * len(word)\n",
    "        guessed_letters = set()\n",
    "        lives_left = 6\n",
    "        wrong_guesses = 0\n",
    "        repeated_guesses = 0\n",
    "        \n",
    "        while lives_left > 0 and '_' in masked_word:\n",
    "            action = self.choose_action(masked_word, guessed_letters, lives_left, training=False)\n",
    "            if action is None:\n",
    "                break\n",
    "            \n",
    "            # Check for repeated guess\n",
    "            if action in guessed_letters:\n",
    "                repeated_guesses += 1\n",
    "            \n",
    "            guessed_letters.add(action)\n",
    "            \n",
    "            # Check if correct\n",
    "            if action in word:\n",
    "                masked_word = ''.join([c if c in guessed_letters else '_' for c in word])\n",
    "            else:\n",
    "                wrong_guesses += 1\n",
    "                lives_left -= 1\n",
    "        \n",
    "        won = '_' not in masked_word\n",
    "        return won, wrong_guesses, repeated_guesses\n",
    "    \n",
    "    def save(self, filename):\n",
    "        \"\"\"Save Q-table\"\"\"\n",
    "        # Convert defaultdict to regular dict for JSON serialization\n",
    "        q_table_dict = {k: dict(v) for k, v in self.q_table.items()}\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(q_table_dict, f)\n",
    "        print(f\"Q-table saved to {filename}\")\n",
    "    \n",
    "    def load(self, filename):\n",
    "        \"\"\"Load Q-table\"\"\"\n",
    "        with open(filename, 'r') as f:\n",
    "            q_table_dict = json.load(f)\n",
    "        self.q_table = defaultdict(lambda: defaultdict(float))\n",
    "        for state, actions in q_table_dict.items():\n",
    "            for action, value in actions.items():\n",
    "                self.q_table[state][action] = value\n",
    "        print(f\"Q-table loaded from {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ce20f3",
   "metadata": {},
   "source": [
    "## 4. Evaluation Function\n",
    "\n",
    "Function to evaluate the agent's performance on a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e48294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_agent(agent, test_words, verbose=True):\n",
    "    \"\"\"Evaluate agent on test set\"\"\"\n",
    "    print(f\"\\nEvaluating agent on {len(test_words)} words...\")\n",
    "    \n",
    "    wins = 0\n",
    "    total_wrong_guesses = 0\n",
    "    total_repeated_guesses = 0\n",
    "    \n",
    "    for i, word in enumerate(test_words):\n",
    "        word = word.lower().strip()\n",
    "        if not word.isalpha():\n",
    "            continue\n",
    "        \n",
    "        won, wrong_guesses, repeated_guesses = agent.play_game(word)\n",
    "        \n",
    "        if won:\n",
    "            wins += 1\n",
    "        total_wrong_guesses += wrong_guesses\n",
    "        total_repeated_guesses += repeated_guesses\n",
    "        \n",
    "        if verbose and (i + 1) % 500 == 0:\n",
    "            print(f\"Evaluated {i + 1}/{len(test_words)} words...\")\n",
    "    \n",
    "    total_games = len(test_words)\n",
    "    success_rate = wins / total_games\n",
    "    avg_wrong_guesses = total_wrong_guesses / total_games\n",
    "    \n",
    "    # Calculate final score using formula: (Success Rate * 2000) - (Total Wrong * 5) - (Total Repeated * 2)\n",
    "    final_score = (success_rate * 2000) - (total_wrong_guesses * 5) - (total_repeated_guesses * 2)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EVALUATION RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total Games:           {total_games}\")\n",
    "    print(f\"Games Won:             {wins}\")\n",
    "    print(f\"Games Lost:            {total_games - wins}\")\n",
    "    print(f\"Success Rate:          {success_rate*100:.2f}%\")\n",
    "    print(f\"Avg Wrong Guesses:     {avg_wrong_guesses:.2f}\")\n",
    "    print(f\"Total Wrong Guesses:   {total_wrong_guesses}\")\n",
    "    print(f\"Total Repeated:        {total_repeated_guesses}\")\n",
    "    print(f\"\\nFINAL SCORE:           {final_score:.2f}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return {\n",
    "        'total_games': total_games,\n",
    "        'wins': wins,\n",
    "        'success_rate': success_rate,\n",
    "        'avg_wrong_guesses': avg_wrong_guesses,\n",
    "        'total_wrong_guesses': total_wrong_guesses,\n",
    "        'total_repeated_guesses': total_repeated_guesses,\n",
    "        'final_score': final_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf9c3aa",
   "metadata": {},
   "source": [
    "## 5. Load Training Corpus\n",
    "\n",
    "Load the corpus of words for training the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3d4449e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INTELLIGENT HANGMAN SOLVER - HMM + RL\n",
      "============================================================\n",
      "\n",
      "Loading corpus...\n",
      "Loaded 50000 words from corpus\n"
     ]
    }
   ],
   "source": [
    "# Load corpus\n",
    "print(\"=\"*60)\n",
    "print(\"INTELLIGENT HANGMAN SOLVER - HMM + RL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nLoading corpus...\")\n",
    "corpus_path = 'corpus.txt'\n",
    "\n",
    "try:\n",
    "    with open(corpus_path, 'r', encoding='utf-8') as f:\n",
    "        corpus_words = [line.strip() for line in f if line.strip()]\n",
    "    print(f\"Loaded {len(corpus_words)} words from corpus\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Could not find corpus file at {corpus_path}\")\n",
    "    print(\"Make sure corpus.txt exists in the current directory.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading corpus: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b944631b",
   "metadata": {},
   "source": [
    "## 6. Train Hidden Markov Model\n",
    "\n",
    "Train the HMM on the corpus to learn letter patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad8fdcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training HMM...\n",
      "Trained HMM for 24 different word lengths\n",
      "HMM saved to hmm_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Train HMM\n",
    "hmm = HiddenMarkovModel()\n",
    "hmm.train(corpus_words)\n",
    "hmm.save('hmm_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33991056",
   "metadata": {},
   "source": [
    "## 7. Train Reinforcement Learning Agent\n",
    "\n",
    "Train the Q-Learning agent using the HMM guidance. This may take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64ba4a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RL agent for 5000 episodes...\n",
      "Episode 500/5000 - Avg Reward: -140.27 - Epsilon: 0.473\n",
      "Episode 1000/5000 - Avg Reward: -83.92 - Epsilon: 0.223\n",
      "Episode 1500/5000 - Avg Reward: -54.05 - Epsilon: 0.106\n",
      "Episode 2000/5000 - Avg Reward: -43.07 - Epsilon: 0.050\n",
      "Episode 2500/5000 - Avg Reward: -45.83 - Epsilon: 0.050\n",
      "Episode 3000/5000 - Avg Reward: -45.02 - Epsilon: 0.050\n",
      "Episode 3500/5000 - Avg Reward: -40.11 - Epsilon: 0.050\n",
      "Episode 4000/5000 - Avg Reward: -42.34 - Epsilon: 0.050\n",
      "Episode 4500/5000 - Avg Reward: -53.76 - Epsilon: 0.050\n",
      "Episode 5000/5000 - Avg Reward: -38.72 - Epsilon: 0.050\n",
      "Training complete!\n",
      "Q-table saved to q_table.json\n"
     ]
    }
   ],
   "source": [
    "# Train RL Agent with more episodes for better performance\n",
    "agent = RLAgent(hmm)\n",
    "rewards = agent.train(corpus_words, episodes=5000, verbose=True)\n",
    "agent.save('q_table.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47be39c2",
   "metadata": {},
   "source": [
    "## 8. Load Test Set\n",
    "\n",
    "Load the test words for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2f0456d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading test set...\n",
      "Loaded 2000 test words\n"
     ]
    }
   ],
   "source": [
    "# Load test set\n",
    "print(\"\\nLoading test set...\")\n",
    "test_path = 'test.txt'\n",
    "\n",
    "try:\n",
    "    with open(test_path, 'r', encoding='utf-8') as f:\n",
    "        test_words = [line.strip() for line in f if line.strip()]\n",
    "    print(f\"Loaded {len(test_words)} test words\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Could not find test file at {test_path}\")\n",
    "    print(\"Make sure test.txt exists in the current directory.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading test file: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2cebe8",
   "metadata": {},
   "source": [
    "## 9. Evaluate Agent Performance\n",
    "\n",
    "Evaluate the trained agent on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82733ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating agent on 2000 words...\n",
      "Evaluated 500/2000 words...\n",
      "Evaluated 1000/2000 words...\n",
      "Evaluated 1500/2000 words...\n",
      "Evaluated 2000/2000 words...\n",
      "\n",
      "============================================================\n",
      "EVALUATION RESULTS\n",
      "============================================================\n",
      "Total Games:           2000\n",
      "Games Won:             660\n",
      "Games Lost:            1340\n",
      "Success Rate:          33.00%\n",
      "Avg Wrong Guesses:     5.18\n",
      "Total Wrong Guesses:   10367\n",
      "Total Repeated:        0\n",
      "\n",
      "FINAL SCORE:           -51175.00\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "results = evaluate_agent(agent, test_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8af812",
   "metadata": {},
   "source": [
    "## 10. Save Results\n",
    "\n",
    "Save the evaluation results to a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3001ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to evaluation_results.json\n"
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "results_path = 'evaluation_results.json'\n",
    "\n",
    "try:\n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    print(f\"\\nResults saved to {results_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving results: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040f6a07",
   "metadata": {},
   "source": [
    "## Optional: Test Individual Words\n",
    "\n",
    "You can test the agent on individual words to see how it plays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f884177e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing word: 'python'\n",
      "Result: Lost\n",
      "Wrong guesses: 6\n",
      "Repeated guesses: 0\n"
     ]
    }
   ],
   "source": [
    "# Example: Test on a specific word\n",
    "test_word = \"python\"\n",
    "won, wrong_guesses, repeated_guesses = agent.play_game(test_word)\n",
    "\n",
    "print(f\"\\nTesting word: '{test_word}'\")\n",
    "print(f\"Result: {'Won' if won else 'Lost'}\")\n",
    "print(f\"Wrong guesses: {wrong_guesses}\")\n",
    "print(f\"Repeated guesses: {repeated_guesses}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b34ac87",
   "metadata": {},
   "source": [
    "## Optional: Load Pre-trained Models\n",
    "\n",
    "If you have previously saved models, you can load them instead of training from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d45da56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained models (optional)\n",
    "# hmm_loaded = HiddenMarkovModel()\n",
    "# hmm_loaded.load('hmm_model.pkl')\n",
    "\n",
    "# agent_loaded = RLAgent(hmm_loaded)\n",
    "# agent_loaded.load('q_table.json')\n",
    "\n",
    "# print(\"Pre-trained models loaded successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
